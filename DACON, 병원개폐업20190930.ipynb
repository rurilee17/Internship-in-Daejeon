{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('C:\\\\Users\\\\BTHANISH\\\\Documents\\\\Thanish\\\\Competition\\\\Dacon\\\\comp 2-Predicting_opening_close_of_hospital')\n",
    "os.chdir('/Users/kookjinkim/Documents/GitHub/admin/2nd_winner_code/2nd_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the train and test files\n",
    "train_prod_df = pd.read_csv('train.csv')\n",
    "test_prod_df = pd.read_csv('test.csv')\n",
    "\n",
    "#Removing the comma in the employee1 and 2 columns in the test dataset and replace it with empty space and convert it to float format.\n",
    "test_prod_df.employee1 = test_prod_df.employee1.astype('str').str.replace(\",\", \"\").astype('float') #string으로 바꾸고, 컴마 없애고, float로 바꿈\n",
    "test_prod_df.employee2 = test_prod_df.employee2.astype('str').str.replace(\",\", \"\").astype('float')\n",
    "\n",
    "#Converting the employee1 and 2 column as float in the train set as done for the test dataset\n",
    "train_prod_df.employee1 = train_prod_df.employee1.astype('float')\n",
    "train_prod_df.employee2 = train_prod_df.employee2.astype('float')\n",
    "train_prod_df.OC= train_prod_df.OC.astype('str').str.replace(\" \",\"\")\n",
    "\n",
    "#Combining the train and test dataset\n",
    "train_test_prod = train_prod_df.append(test_prod_df) #append는 뒤에 붙는다. pandas는 밑에 붙는다.\n",
    "\n",
    "#Get the object and numeric columns seperately \n",
    "factor_columns = train_test_prod.select_dtypes(include = ['object']).columns #object는 string임. column정보만 빼옴.\n",
    "numeric_columns = train_test_prod.columns.difference(factor_columns)#factor columns가 아닌거(차집합)만 빼온거\n",
    "\n",
    "#After analysis realized that the bed counts of these two hospitals may have had wrong entries.\n",
    "#Filling up the empty instkind and bedCount for hospital id 430 and 413\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['instkind']] = 'dental_clinic'\n",
    "train_test_prod.loc[train_test_prod.inst_id == 430, ['bedCount']] = 0\n",
    "train_test_prod.loc[train_test_prod.inst_id == 413, ['bedCount']] = -999\n",
    "\n",
    "#Fill the empty values in the object columns as \"Not sure\"\n",
    "train_test_prod[factor_columns] = train_test_prod[factor_columns].fillna('Not_sure') #결측지에 string으로 넣어줌.\n",
    "\n",
    "#Fill all the empty values in the numeric columns as -999\n",
    "train_test_prod[numeric_columns] = train_test_prod[numeric_columns].fillna(-999)\n",
    "\n",
    "#Convert all the object columns to numeric since the ML algorithms don't accept object features directly \n",
    "fac_le = LabelEncoder() #함수나 클래스다. 변수에는 괄호 안씀.-인덱스 쓰는거. 레이블인코더 - \n",
    "train_test_prod[factor_columns] = train_test_prod.loc[:,factor_columns].apply(lambda x : fac_le.fit_transform(x)) \n",
    "\n",
    "#Splitting back data to train prod and test prod\n",
    "train_prod = train_test_prod.loc[train_test_prod.OC != 0,]\n",
    "test_prod = train_test_prod.loc[train_test_prod.OC == 0,]\n",
    "train_prod['OC'] = train_prod['OC'] - 1\n",
    "\n",
    "#Obtain the submission ID to create the submission file later\n",
    "sub_id = test_prod.inst_id\n",
    "\n",
    "#Get the dependent and independent column\n",
    "dep = 'OC'\n",
    "indep = train_prod.columns.difference([dep])\n",
    "\n",
    "train_prod_X = train_prod[indep]\n",
    "train_prod_Y = train_prod[dep]\n",
    "test_prod_X = test_prod[indep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ Random Forest\n",
    "############################################################################\n",
    "estimators = 10 #\n",
    "np.random.seed(100)\n",
    "RF_prod = RandomForestClassifier(n_estimators = estimators) #랜덤포레스트 가지고 분류\n",
    "RF_prod_model = RF_prod.fit(train_prod_X, train_prod_Y) #학습시키고\n",
    "RF_prod_prediction = RF_prod.predict_proba(test_prod_X)[:,1] #예측시키고 확률계산.\n",
    "\n",
    "sub_RF = pd.DataFrame({'inst_id' : sub_id , 'OC' : RF_prod_prediction })\n",
    "sub_RF = sub_RF[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "############ GBM\n",
    "############################################################################\n",
    "estimators = 10\n",
    "np.random.seed(100)\n",
    "GBM_prod = GradientBoostingClassifier(n_estimators = estimators)\n",
    "GBM_prod_model = GBM_prod.fit(train_prod_X, train_prod_Y)\n",
    "GBM_prod_prediction = GBM_prod.predict_proba(test_prod_X)[:,1]\n",
    "\n",
    "sub_GBM = pd.DataFrame({'inst_id' : sub_id , 'OC' : GBM_prod_prediction })\n",
    "sub_GBM = sub_GBM[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "############ XGBOOST\n",
    "############################################################################\n",
    "dtrain_prod = xgb.DMatrix(data = train_prod_X, label = train_prod_Y) #얘는 함수/클래스 아니고 패키지에서 불러왔음.\n",
    "dtest_prod = xgb.DMatrix(data = test_prod_X)\n",
    "\n",
    "#Custom error function for the XGB model\n",
    "threshold = 0.5\n",
    "def eval_error(preds, dtrain):\n",
    "    labels = dtrain.get_label() #트레인에서 레이블정보 빼는거고\n",
    "    preds = (preds > threshold ).astype('float') #값이 크면, 묶어서 float로.\n",
    "    return \"accuracy\", accuracy_score(labels, preds)\n",
    "    \n",
    "\n",
    "param = {'objective' : 'binary:logistic',\n",
    "         'max_depth' : 6,\n",
    "         'eta': 0.3,\n",
    "         'colsample_bytree' : 1,\n",
    "         'subsample' : 1,\n",
    "         'silent' : 0\n",
    "         }\n",
    "\n",
    "nrounds = 2\n",
    "\n",
    "np.random.seed(100)\n",
    "xgb_model = xgb.train(param, \n",
    "                      dtrain_prod, \n",
    "                      num_boost_round = nrounds ,\n",
    "                      feval = eval_error,\n",
    "                      #maximize = True,\n",
    "                      #early_stopping_rounds = 10,\n",
    "                      )\n",
    "\n",
    "XGB_prediction = xgb_model.predict(dtest_prod)\n",
    "\n",
    "sub_XGB= pd.DataFrame({'inst_id' : sub_id , 'OC' : XGB_prediction })\n",
    "sub_XGB= sub_XGB[['inst_id', 'OC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PLotting the feature importance\n",
    "xgb_Imp = pd.DataFrame({'Features' : list(xgb_model.get_score().keys()), \n",
    "                        'Importance' : list(xgb_model.get_score().values())}).sort_values(['Importance'])\n",
    "plt.figure()\n",
    "sns.barplot(xgb_Imp.Importance, xgb_Imp.Features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################\n",
    "#Ensembling the three models\n",
    "############################################################################\n",
    "\n",
    "#Forming the ensemble dataset of the 3 models\n",
    "ensemble = pd.DataFrame()\n",
    "ensemble['inst_id'] = sub_XGB['inst_id']\n",
    "ensemble['XGB'] = sub_XGB['OC']\n",
    "ensemble['GBM'] = sub_GBM['OC']\n",
    "ensemble['RF'] = sub_RF['OC']\n",
    "\n",
    "# Taking the average of all 3 models\n",
    "ensemble['ens'] = (ensemble['XGB'] + ensemble['GBM'] + ensemble['RF'])/3\n",
    "ensemble['OC'] = (ensemble['ens'] > 0.7).astype('int') #0.7 as the threshold and above that the hospital is closed.\n",
    "\n",
    "#Printing to see all the hospitals that are classified as closed \n",
    "print(ensemble.loc[ensemble['OC'] == 0, ])\n",
    "\n",
    "ensemble = ensemble.loc[:, ['inst_id', 'OC']]\n",
    "\n",
    "#ensemble.to_csv('ens_XGB_7_RF_4_GBM_2_39.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
