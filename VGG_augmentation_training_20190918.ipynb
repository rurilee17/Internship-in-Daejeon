{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\affinity\\anaconda3\\lib\\site-packages (1.14.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.2)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (0.1.7)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.22.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.2.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\affinity\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers, models, datasets, backend\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset API 설정(train에 적용시키는 코드 못찾음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0918 14:09:53.548762  6532 deprecation.py:323] From <ipython-input-3-c65eb7868f23>:18: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'image': array([[[[ 80,  92, 122],\n",
      "         [ 79,  90, 126],\n",
      "         [ 77,  88, 124],\n",
      "         ...,\n",
      "         [136, 141, 168],\n",
      "         [125, 129, 157],\n",
      "         [147, 147, 163]],\n",
      "\n",
      "        [[ 69,  83, 118],\n",
      "         [ 71,  84, 126],\n",
      "         [ 74,  86, 129],\n",
      "         ...,\n",
      "         [135, 140, 169],\n",
      "         [124, 129, 157],\n",
      "         [124, 124, 140]],\n",
      "\n",
      "        [[ 68,  82, 120],\n",
      "         [ 70,  83, 127],\n",
      "         [ 72,  85, 130],\n",
      "         ...,\n",
      "         [133, 138, 168],\n",
      "         [124, 128, 156],\n",
      "         [124, 124, 140]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 26,  38,  66],\n",
      "         [ 30,  42,  71],\n",
      "         [ 30,  43,  72],\n",
      "         ...,\n",
      "         [ 27,  43,  73],\n",
      "         [ 28,  38,  67],\n",
      "         [ 83,  90, 104]],\n",
      "\n",
      "        [[ 31,  40,  61],\n",
      "         [ 37,  46,  67],\n",
      "         [ 34,  44,  64],\n",
      "         ...,\n",
      "         [ 43,  52,  79],\n",
      "         [ 45,  55,  77],\n",
      "         [ 90, 100, 108]],\n",
      "\n",
      "        [[ 97, 102, 114],\n",
      "         [ 85,  89, 101],\n",
      "         [ 86,  90, 102],\n",
      "         ...,\n",
      "         [ 79,  84,  99],\n",
      "         [ 75,  83,  91],\n",
      "         [115, 123, 122]]],\n",
      "\n",
      "\n",
      "       [[[138, 106,  33],\n",
      "         [136, 106,  32],\n",
      "         [128, 106,  39],\n",
      "         ...,\n",
      "         [165, 140,  72],\n",
      "         [121, 118,  92],\n",
      "         [192, 211, 220]],\n",
      "\n",
      "        [[134, 101,  35],\n",
      "         [146, 117,  57],\n",
      "         [110,  93,  51],\n",
      "         ...,\n",
      "         [175, 150,  85],\n",
      "         [ 98,  95,  68],\n",
      "         [176, 195, 203]],\n",
      "\n",
      "        [[137, 102,  40],\n",
      "         [134, 106,  61],\n",
      "         [112,  99,  83],\n",
      "         ...,\n",
      "         [173, 148,  83],\n",
      "         [ 99,  96,  69],\n",
      "         [178, 197, 204]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[118,  94,  30],\n",
      "         [117,  88,  20],\n",
      "         [116,  87,  20],\n",
      "         ...,\n",
      "         [119, 103,  49],\n",
      "         [ 91,  90,  65],\n",
      "         [175, 189, 189]],\n",
      "\n",
      "        [[127, 132, 118],\n",
      "         [103, 101,  83],\n",
      "         [105, 103,  82],\n",
      "         ...,\n",
      "         [ 97,  96,  82],\n",
      "         [113, 119, 117],\n",
      "         [185, 201, 210]],\n",
      "\n",
      "        [[206, 229, 250],\n",
      "         [194, 213, 234],\n",
      "         [192, 216, 232],\n",
      "         ...,\n",
      "         [194, 214, 228],\n",
      "         [197, 218, 231],\n",
      "         [209, 232, 245]]],\n",
      "\n",
      "\n",
      "       [[[ 27,  31,  25],\n",
      "         [ 28,  31,  27],\n",
      "         [ 25,  25,  24],\n",
      "         ...,\n",
      "         [ 12,  16,  16],\n",
      "         [ 12,  19,  17],\n",
      "         [ 12,  23,  20]],\n",
      "\n",
      "        [[ 23,  27,  21],\n",
      "         [ 29,  31,  26],\n",
      "         [ 32,  33,  29],\n",
      "         ...,\n",
      "         [ 25,  27,  22],\n",
      "         [ 21,  23,  19],\n",
      "         [ 20,  25,  22]],\n",
      "\n",
      "        [[ 19,  26,  21],\n",
      "         [ 19,  25,  20],\n",
      "         [ 20,  24,  20],\n",
      "         ...,\n",
      "         [ 32,  34,  24],\n",
      "         [ 36,  38,  32],\n",
      "         [ 38,  40,  35]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 15,  20,  23],\n",
      "         [ 14,  16,  18],\n",
      "         [ 21,  23,  25],\n",
      "         ...,\n",
      "         [106, 119,  68],\n",
      "         [109, 124,  69],\n",
      "         [ 93, 106,  60]],\n",
      "\n",
      "        [[ 41,  52,  34],\n",
      "         [ 35,  45,  29],\n",
      "         [ 37,  46,  34],\n",
      "         ...,\n",
      "         [110, 125,  74],\n",
      "         [ 75,  87,  54],\n",
      "         [ 46,  54,  39]],\n",
      "\n",
      "        [[135, 150,  92],\n",
      "         [ 96, 111,  63],\n",
      "         [ 75,  89,  50],\n",
      "         ...,\n",
      "         [110, 126,  82],\n",
      "         [ 52,  65,  45],\n",
      "         [ 14,  22,  19]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 32,  26,  14],\n",
      "         [ 63,  47,  40],\n",
      "         [143, 110, 112],\n",
      "         ...,\n",
      "         [ 36,  18,  24],\n",
      "         [ 35,  17,  17],\n",
      "         [ 59,  56,  44]],\n",
      "\n",
      "        [[ 26,  23,  16],\n",
      "         [ 82,  66,  67],\n",
      "         [176, 139, 150],\n",
      "         ...,\n",
      "         [ 20,  23,  23],\n",
      "         [ 40,  48,  36],\n",
      "         [ 56,  70,  44]],\n",
      "\n",
      "        [[ 48,  36,  32],\n",
      "         [128,  99, 104],\n",
      "         [191, 139, 155],\n",
      "         ...,\n",
      "         [ 58,  60,  46],\n",
      "         [ 74,  88,  63],\n",
      "         [ 72,  92,  54]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[198, 143, 152],\n",
      "         [200, 148, 168],\n",
      "         [204, 156, 175],\n",
      "         ...,\n",
      "         [174, 113, 122],\n",
      "         [144,  83,  98],\n",
      "         [135,  77,  91]],\n",
      "\n",
      "        [[207, 155, 167],\n",
      "         [212, 162, 183],\n",
      "         [212, 165, 183],\n",
      "         ...,\n",
      "         [147,  87,  98],\n",
      "         [132,  73,  93],\n",
      "         [120,  65,  83]],\n",
      "\n",
      "        [[212, 165, 175],\n",
      "         [216, 168, 184],\n",
      "         [210, 162, 173],\n",
      "         ...,\n",
      "         [142,  87,  96],\n",
      "         [128,  76,  92],\n",
      "         [119,  71,  85]]],\n",
      "\n",
      "\n",
      "       [[[ 59,  78,  85],\n",
      "         [ 60,  79,  86],\n",
      "         [ 66,  85,  92],\n",
      "         ...,\n",
      "         [ 91, 113, 110],\n",
      "         [ 93, 115, 112],\n",
      "         [100, 121, 119]],\n",
      "\n",
      "        [[ 56,  75,  82],\n",
      "         [ 56,  75,  82],\n",
      "         [ 65,  84,  91],\n",
      "         ...,\n",
      "         [ 95, 117, 114],\n",
      "         [107, 129, 126],\n",
      "         [106, 126, 124]],\n",
      "\n",
      "        [[ 64,  83,  90],\n",
      "         [ 59,  78,  85],\n",
      "         [ 61,  80,  87],\n",
      "         ...,\n",
      "         [ 92, 114, 111],\n",
      "         [ 95, 118, 114],\n",
      "         [100, 121, 119]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 77,  80,  72],\n",
      "         [ 83,  88,  80],\n",
      "         [ 96, 103,  95],\n",
      "         ...,\n",
      "         [132, 134, 111],\n",
      "         [123, 136, 119],\n",
      "         [102, 127, 114]],\n",
      "\n",
      "        [[ 43,  51,  48],\n",
      "         [ 59,  68,  66],\n",
      "         [ 67,  77,  78],\n",
      "         ...,\n",
      "         [143, 136, 109],\n",
      "         [142, 145, 121],\n",
      "         [128, 142, 124]],\n",
      "\n",
      "        [[ 58,  68,  71],\n",
      "         [ 75,  87,  90],\n",
      "         [ 86,  99, 105],\n",
      "         ...,\n",
      "         [135, 122,  91],\n",
      "         [161, 155, 124],\n",
      "         [171, 172, 149]]],\n",
      "\n",
      "\n",
      "       [[[129, 144, 181],\n",
      "         [128, 142, 179],\n",
      "         [128, 142, 179],\n",
      "         ...,\n",
      "         [117, 132, 175],\n",
      "         [116, 131, 174],\n",
      "         [115, 130, 173]],\n",
      "\n",
      "        [[127, 141, 178],\n",
      "         [124, 138, 175],\n",
      "         [124, 138, 175],\n",
      "         ...,\n",
      "         [112, 127, 169],\n",
      "         [111, 126, 169],\n",
      "         [111, 126, 169]],\n",
      "\n",
      "        [[125, 139, 176],\n",
      "         [122, 136, 173],\n",
      "         [122, 136, 173],\n",
      "         ...,\n",
      "         [109, 124, 167],\n",
      "         [108, 123, 166],\n",
      "         [108, 123, 166]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 41,  44,  83],\n",
      "         [ 39,  42,  81],\n",
      "         [ 38,  41,  80],\n",
      "         ...,\n",
      "         [ 36,  41,  83],\n",
      "         [ 34,  39,  81],\n",
      "         [ 32,  37,  79]],\n",
      "\n",
      "        [[ 39,  39,  79],\n",
      "         [ 39,  39,  79],\n",
      "         [ 38,  39,  78],\n",
      "         ...,\n",
      "         [ 39,  44,  84],\n",
      "         [ 38,  43,  83],\n",
      "         [ 36,  41,  81]],\n",
      "\n",
      "        [[ 37,  36,  76],\n",
      "         [ 37,  35,  75],\n",
      "         [ 36,  34,  74],\n",
      "         ...,\n",
      "         [ 35,  40,  78],\n",
      "         [ 35,  40,  79],\n",
      "         [ 37,  42,  80]]]], dtype=uint8)}, array([[8],\n",
      "       [5],\n",
      "       [2],\n",
      "       [4],\n",
      "       [3],\n",
      "       [7],\n",
      "       [2],\n",
      "       [6],\n",
      "       [5],\n",
      "       [1]], dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "#Dataset 생성 : tf.data.Dataset을 생성하는 것으로 메모리에 한번에 로드하여 사용할 수도 있으며, 동적으로 전달하여 사용할 수도 있습니다.\n",
    "#Iterator 생성 : 데이터를 조회할때 사용되는 iterator 를 생성합니다.\n",
    "#데이터 사용 : 실제 모델에 데이터를 입력하거나, 읽게 됩니다.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "#dataset api\n",
    "train, test = tf.keras.datasets.cifar10.load_data() #데이터불러오기\n",
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({\"image\":x_train}, y_train))#데이터셋 생성코드\n",
    "dataset = dataset.shuffle(100000).repeat().batch(10) \n",
    "#위의 코드에서 생성된 Dataset 을 shuffle 함수를 이용하여 섞습니다. shuffle 함수는 고정된 버퍼 크기로 데이터를 섞는데, \n",
    "#데이터가 완전히 랜덤적으로 뒤섞기 위해서는 입력된 데이터 크기보다 큰 수를 입력해 주셔야 합니다.\n",
    "#repeat라는 함수는 데이터셋을 읽다가 마지막에 도달했을 경우, 다시 처음부터 조회하는 함수입니다. \n",
    "#batch 함수는 데이터를 읽어올 개수를 지정하는 함수입니다.\n",
    "iterator = dataset.make_one_shot_iterator()#one-shot iterator 생성,iterator 상태를 처음 초기화하거나 다시 초기화 하는 동작을 합니다.\n",
    "next_element = iterator.get_next() #다음 항목에 연결되어 있는 tf.Tensor 객체를 리턴합니다\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(next_element)) #세션을 실행시켜서, 데이터를 가져와서 사용 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(50000, 32, 32, 3) (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train), type(y_train))\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape) #형태확인\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네트워크 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0918 14:10:22.654692  6532 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0918 14:10:22.658622  6532 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0918 14:10:22.665013  6532 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0918 14:10:22.706429  6532 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0918 14:10:22.913268  6532 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0918 14:10:22.919288  6532 deprecation.py:506] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#functional api\n",
    "\n",
    "input = Input(shape=(32,32,3))\n",
    "conv1 = Conv2D(64,kernel_size=3,activation='relu',padding='same')(input)\n",
    "conv2 = Conv2D(64,kernel_size=3,activation='relu',padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "conv3 = Conv2D(128,kernel_size=3,activation='relu',padding='same')(pool1)\n",
    "conv4 = Conv2D(128,kernel_size=3,activation='relu',padding='same')(conv3)\n",
    "pool2 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "conv5 = Conv2D(256,kernel_size=3,activation='relu',padding='same')(pool2)\n",
    "conv6 = Conv2D(256,kernel_size=3,activation='relu',padding='same')(conv5)\n",
    "conv7 = Conv2D(256,kernel_size=3,activation='relu',padding='same')(conv6)\n",
    "pool3 = MaxPooling2D(pool_size=(2,2))(conv7)\n",
    "conv8 = Conv2D(512,kernel_size=3,activation='relu',padding='same')(pool3)\n",
    "conv9 = Conv2D(512,kernel_size=3,activation='relu',padding='same')(conv8)\n",
    "conv10 = Conv2D(512,kernel_size=3,activation='relu',padding='same')(conv9)\n",
    "pool4= MaxPooling2D(pool_size=(2,2))(conv10)\n",
    "conv11 = Conv2D(512,kernel_size=3,activation='relu',padding='same')(pool4)\n",
    "conv12= Conv2D(512,kernel_size=3,activation='relu',padding='same')(conv11)\n",
    "conv13 = Conv2D(512,kernel_size=3,activation='relu',padding='same')(conv12)\n",
    "pool5= MaxPooling2D(pool_size=(2,2))(conv13)\n",
    "flat = Flatten()(pool5)\n",
    "dense1 = Dense(4096,activation='relu')(flat)\n",
    "drop1 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(4096,activation='relu')(drop1)\n",
    "drop2 = Dropout(0.5)(dense2)\n",
    "output = Dense(10,activation='softmax')(drop2)\n",
    "model = Model(inputs = input,outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,638,218\n",
      "Trainable params: 33,638,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0918 14:10:23.121890  6532 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0918 14:10:23.150550  6532 deprecation_wrapper.py:119] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['acc']) # For a multi-class classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0918 14:10:26.311388  6532 deprecation.py:323] From C:\\Users\\Affinity\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1563/1562 [==============================] - 2837s 2s/step - loss: 14.4996 - acc: 0.0999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x231ad975668>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "\n",
    "#기능별 정규화에 필요한 계산량\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# 실시간 데이터 기능 보강을 사용하여 배치에 모델을 fit :\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset API, augmentation 없이 훈련 시키는 내용(아래)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x_train, y_train, epochs = 1, batch_size =64) \n",
    "#이 코드는 작동함 - 지난주에 했던 코드라서 끝까지 안돌림."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터증식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터증식 제너레이터를 사용해서 훈련시키기\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일경로 지정하기\n",
    "#파일 내 test, train 이 제대로 안나눠져있고, \n",
    "#train_data는 data_batch_1~5 이런식으로 되어있음.그리고 저걸 넣으면 아래 코드가 오류남\n",
    "train_dir = r'C:/Users/Affinity/cifar-10-batches-py' \n",
    "test_dir = r'C:/Users/Affinity/cifar-10-batches-py/test_batch'\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "#여기서부터 문제 안풀림\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150,150),batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DirectoryIterator' object has no attribute 'ndim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-66ddcb7b989b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#여기도 어떻게 해결해야할지 모르겠음.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstandardize_single_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_single_array\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 'Got tensor with shape: %s' % str(shape))\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DirectoryIterator' object has no attribute 'ndim'"
     ]
    }
   ],
   "source": [
    "#여기도 어떻게 해결해야할지 모르겠음.\n",
    "history = model.fit(train_generator, steps_per_epoch=50, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NumpyArrayIterator' object has no attribute 'flow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-f26196114875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit_generator(train_generator.flow(x_train, y_train, batch_size=32),\n\u001b[0m\u001b[0;32m      2\u001b[0m                     steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NumpyArrayIterator' object has no attribute 'flow'"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(x_train, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
